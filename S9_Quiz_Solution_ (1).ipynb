:
from datetime import  datetime
print("Current Date/Time: ", datetime.now())
Current Date/Time:  2020-03-21 18:53:42.515271
In [2]:
from google.colab import drive
drive.mount('/content/gdrive')
%cd /content/gdrive/My\ Drive/S9F
Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly

Enter your authorization code:
··········
Mounted at /content/gdrive
/content/gdrive/My Drive/S9F
In [0]:
import torch.nn as nn
import torch.optim as optim
from model import QuizDNN
import matplotlib.pyplot as plt
from torchsummary import summary
from data import data
from Data.dataset import CIFAR10
from display import display
In [4]:
trainset, testset, train_loader, test_loader, classes =data()
CUDA Available? True
Files already downloaded and verified
Files already downloaded and verified
In [0]:
import model
net = QuizDNN.QuizDNN()
In [0]:
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
In [9]:
import torch
use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")
print(device)
model = net.to(device)
summary(model, input_size=(3, 32, 32))
cuda
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 32, 32]           1,792
              ReLU-2           [-1, 64, 32, 32]               0
       BatchNorm2d-3           [-1, 64, 32, 32]             128
            Conv2d-4           [-1, 64, 32, 32]          36,928
              ReLU-5           [-1, 64, 32, 32]               0
       BatchNorm2d-6           [-1, 64, 32, 32]             128
            Conv2d-7           [-1, 64, 32, 32]          36,928
              ReLU-8           [-1, 64, 32, 32]               0
       BatchNorm2d-9           [-1, 64, 32, 32]             128
        MaxPool2d-10           [-1, 64, 16, 16]               0
           Conv2d-11           [-1, 64, 16, 16]          36,928
             ReLU-12           [-1, 64, 16, 16]               0
      BatchNorm2d-13           [-1, 64, 16, 16]             128
           Conv2d-14           [-1, 64, 16, 16]          36,928
             ReLU-15           [-1, 64, 16, 16]               0
      BatchNorm2d-16           [-1, 64, 16, 16]             128
           Conv2d-17           [-1, 64, 16, 16]          36,928
             ReLU-18           [-1, 64, 16, 16]               0
      BatchNorm2d-19           [-1, 64, 16, 16]             128
        MaxPool2d-20             [-1, 64, 8, 8]               0
           Conv2d-21             [-1, 64, 8, 8]          36,928
             ReLU-22             [-1, 64, 8, 8]               0
      BatchNorm2d-23             [-1, 64, 8, 8]             128
           Conv2d-24             [-1, 64, 8, 8]          36,928
             ReLU-25             [-1, 64, 8, 8]               0
      BatchNorm2d-26             [-1, 64, 8, 8]             128
           Conv2d-27             [-1, 64, 8, 8]          36,928
             ReLU-28             [-1, 64, 8, 8]               0
      BatchNorm2d-29             [-1, 64, 8, 8]             128
AdaptiveAvgPool2d-30             [-1, 64, 1, 1]               0
           Linear-31                   [-1, 10]             650
================================================================
Total params: 299,018
Trainable params: 299,018
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.01
Forward/backward pass size (MB): 6.06
Params size (MB): 1.14
Estimated Total Size (MB): 7.22
----------------------------------------------------------------
In [10]:
from callbacks import lr_scheduler

from traintest import train,test
lr_step_size=10
lr_gamma=0.1
scheduler = lr_scheduler(optimizer,lr_step_size, lr_gamma)
losses = []
accuracies = []
correct_samples = []
incorrect_samples = []
EPOCHS = 10
for epoch in range(EPOCHS):
    print("EPOCH:", epoch)
    train(model,device,train_loader, optimizer, epoch, criterion)
    test(model, device, test_loader)
  0%|          | 0/782 [00:00<?, ?it/s]
EPOCH: 0
Loss=1.272868037223816 Batch_id=781 Accuracy=44.42: 100%|██████████| 782/782 [00:21<00:00, 37.18it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.4791, Accuracy: 5209/10000 (52.09%)

EPOCH: 1
Loss=1.2868573665618896 Batch_id=781 Accuracy=58.62: 100%|██████████| 782/782 [00:20<00:00, 37.59it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.3932, Accuracy: 6068/10000 (60.68%)

EPOCH: 2
Loss=1.3784115314483643 Batch_id=781 Accuracy=65.10: 100%|██████████| 782/782 [00:20<00:00, 37.79it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.3369, Accuracy: 6631/10000 (66.31%)

EPOCH: 3
Loss=1.3497140407562256 Batch_id=781 Accuracy=69.47: 100%|██████████| 782/782 [00:20<00:00, 37.66it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.3157, Accuracy: 6843/10000 (68.43%)

EPOCH: 4
Loss=1.3808534145355225 Batch_id=781 Accuracy=73.13: 100%|██████████| 782/782 [00:20<00:00, 37.68it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.3059, Accuracy: 6941/10000 (69.41%)

EPOCH: 5
Loss=0.6635091304779053 Batch_id=781 Accuracy=76.02: 100%|██████████| 782/782 [00:20<00:00, 37.55it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.2788, Accuracy: 7212/10000 (72.12%)

EPOCH: 6
Loss=0.40931910276412964 Batch_id=781 Accuracy=78.65: 100%|██████████| 782/782 [00:20<00:00, 37.61it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.3007, Accuracy: 6993/10000 (69.93%)

EPOCH: 7
Loss=0.44050735235214233 Batch_id=781 Accuracy=80.67: 100%|██████████| 782/782 [00:20<00:00, 37.89it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.2223, Accuracy: 7777/10000 (77.77%)

EPOCH: 8
Loss=0.3369050621986389 Batch_id=781 Accuracy=82.95: 100%|██████████| 782/782 [00:20<00:00, 37.37it/s]
  0%|          | 0/782 [00:00<?, ?it/s]
Test set: Average loss: 0.2455, Accuracy: 7545/10000 (75.45%)

EPOCH: 9
Loss=0.6546609401702881 Batch_id=781 Accuracy=84.29: 100%|██████████| 782/782 [00:20<00:00, 38.45it/s]
Test set: Average loss: 0.2189, Accuracy: 7811/10000 (78.11%)
